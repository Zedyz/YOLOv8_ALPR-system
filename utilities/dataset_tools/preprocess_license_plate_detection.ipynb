{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Used for converting annotations into OBB format and splitting files into 80/20/10 train/val/test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb037d8d369c8851"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bedb82169c11f58",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "source_dir = 'cars-me'\n",
    "images_dir = 'images'\n",
    "texts_dir = 'annotations'\n",
    "\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(texts_dir, exist_ok=True)\n",
    "files = os.listdir(source_dir)\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(source_dir, file)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp')):\n",
    "            shutil.move(file_path, os.path.join(images_dir, file))\n",
    "        elif file.lower().endswith('.txt'):\n",
    "            shutil.move(file_path, os.path.join(texts_dir, file))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T11:31:10.082143900Z",
     "start_time": "2024-02-09T11:31:07.278717300Z"
    }
   },
   "id": "aaaabbddb432933d",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed.\n"
     ]
    }
   ],
   "source": [
    "source_dir = 'annotations'\n",
    "output_dir = 'new_annotations'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def process_record(record):\n",
    "    lines = record.split('\\n')\n",
    "    corners_line = next(line for line in lines if line.startswith('corners:'))\n",
    "    corners_str = corners_line.split('corners: ')[1]\n",
    "    corners = [int(coord) for point in corners_str.split() for coord in point.split(',')]\n",
    "    \n",
    "    class_id = 0\n",
    "    image_width, image_height = 1280, 720  # Adjust these values as needed    \n",
    "    normalized_corners = [corners[i] / image_width if i % 2 == 0 else corners[i] / image_height for i in range(len(corners))]    \n",
    "    formatted_annotation = f'{class_id} ' + ' '.join(f'{coord:.15f}' for coord in normalized_corners)\n",
    "    \n",
    "    return formatted_annotation\n",
    "\n",
    "for txt_file in glob.glob(os.path.join(source_dir, '*.txt')):\n",
    "    with open(txt_file, 'r') as infile:\n",
    "        content = infile.read().strip()\n",
    "        formatted_annotation = process_record(content)\n",
    "        \n",
    "        output_file_path = os.path.join(output_dir, os.path.basename(txt_file))        \n",
    "        with open(output_file_path, 'w') as outfile:\n",
    "            outfile.write(formatted_annotation + '\\n')\n",
    "\n",
    "print(\"Conversion completed.\")"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-09T11:42:17.861912Z",
     "start_time": "2024-02-09T11:42:16.128971100Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split and organized successfully.\n"
     ]
    }
   ],
   "source": [
    "images_dir = './Images'\n",
    "annotations_dir = './Annotations'\n",
    "\n",
    "base_output_dir = './Dataset'\n",
    "\n",
    "sets = ['train', 'valid', 'test']\n",
    "categories = ['images', 'labels']\n",
    "\n",
    "for set_name in sets:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(base_output_dir, set_name, category), exist_ok=True)\n",
    "\n",
    "image_filenames = [os.path.splitext(f)[0] for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
    "\n",
    "train_filenames, temp_filenames = train_test_split(image_filenames, test_size=0.3, random_state=42)  # 70% for training, 30% for valid+test\n",
    "valid_filenames, test_filenames = train_test_split(temp_filenames, test_size=(1/3), random_state=42)  # Split the 30% into 20% valid, 10% test\n",
    "\n",
    "def copy_files(filenames, src_dir, dst_dir, category, extension):\n",
    "    for filename in filenames:\n",
    "        src_file = os.path.join(src_dir, filename + extension)\n",
    "        dst_file = os.path.join(dst_dir, category, filename + extension)\n",
    "        shutil.copy(src_file, dst_file)\n",
    "\n",
    "for set_name, filenames in zip(['train', 'valid', 'test'], [train_filenames, valid_filenames, test_filenames]):\n",
    "    images_output_dir = os.path.join(base_output_dir, set_name)\n",
    "    labels_output_dir = images_output_dir  # Images and labels are stored in the same set directory but different category directories\n",
    "    copy_files(filenames, images_dir, images_output_dir, 'images', '.jpg')  # Adjust extension as necessary\n",
    "    copy_files(filenames, annotations_dir, labels_output_dir, 'labels', '.txt')  # Assuming .txt annotation files\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T12:15:50.774656500Z",
     "start_time": "2024-02-09T12:15:44.169914100Z"
    }
   },
   "id": "96ec0a4c12ed7acb",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Used for creating licence plate dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c04e337abef44d0a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generation and organization completed.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration parameters\n",
    "base_dir = 'dataset'\n",
    "font_path = 'license-plate.ttf'\n",
    "image_size = (30, 49)  # width, height in pixels\n",
    "samples_per_char = 5\n",
    "base_font_size = 50  # Adjusted for more noticeable size variation\n",
    "max_font_size_variation = 5  # Increased variation range\n",
    "position_variation_range = 3  # Reduced variation range for position\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(annotations_dir, exist_ok=True)\n",
    "\n",
    "# Character to class ID mapping\n",
    "char_to_id = {str(i): i for i in range(10)}\n",
    "char_to_id.update({chr(65+i): 10+i for i in range(26)})\n",
    "\n",
    "for char in string.digits + string.ascii_uppercase:\n",
    "    for sample in range(samples_per_char):\n",
    "        img = Image.new('RGB', image_size, 'white')\n",
    "        d = ImageDraw.Draw(img)\n",
    "        \n",
    "        # Applying variation in font size\n",
    "        font_size = base_font_size + random.randint(-max_font_size_variation, max_font_size_variation)\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "        \n",
    "        # Applying reduced variation in position\n",
    "        position_x = image_size[0] // 2 + random.randint(-position_variation_range, position_variation_range)\n",
    "        position_y = image_size[1] // 2 + random.randint(-position_variation_range, position_variation_range)\n",
    "\n",
    "        d.text((position_x, position_y), char, fill=\"black\", font=font, anchor=\"mm\")\n",
    "\n",
    "        # Save the image\n",
    "        filename = f\"{char}_{sample}.png\"\n",
    "        img.save(os.path.join(images_dir, filename))\n",
    "\n",
    "        # Bounding box information (assuming fixed proportion of image size)\n",
    "        norm_x1, norm_y1, norm_x2, norm_y2 = 0.1, 0.1, 0.9, 0.9\n",
    "        class_id = char_to_id[char]\n",
    "        bbox_info = f\"{class_id} {norm_x1} {norm_y1} {norm_x2} {norm_y1} {norm_x2} {norm_y2} {norm_x1} {norm_y2}\"\n",
    "\n",
    "        txt_filename = f\"{char}_{sample}.txt\"\n",
    "        with open(os.path.join(annotations_dir, txt_filename), 'w') as file:\n",
    "            file.write(bbox_info)\n",
    "\n",
    "\n",
    "all_filenames = [f\"{char}_{sample}\" for char in string.ascii_uppercase + ''.join(map(str, range(10))) for sample in range(samples_per_char)]\n",
    "\n",
    "train_files, test_files = train_test_split(all_filenames, test_size=0.2, random_state=42)\n",
    "valid_files, test_files = train_test_split(test_files, test_size=0.5, random_state=42)  # Adjusts to 10% for test\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    os.makedirs(os.path.join(base_dir, split, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(base_dir, split, 'labels'), exist_ok=True)\n",
    "\n",
    "def move_files(file_list, source_dir, dest_dir, file_ext):\n",
    "    for filename in file_list:\n",
    "        shutil.move(os.path.join(source_dir, filename + file_ext), os.path.join(dest_dir, filename + file_ext))\n",
    "\n",
    "# Move the files\n",
    "move_files(train_files, images_dir, os.path.join(base_dir, 'train', 'images'), '.png')\n",
    "move_files(train_files, annotations_dir, os.path.join(base_dir, 'train', 'labels'), '.txt')\n",
    "\n",
    "move_files(valid_files, images_dir, os.path.join(base_dir, 'valid', 'images'), '.png')\n",
    "move_files(valid_files, annotations_dir, os.path.join(base_dir, 'valid', 'labels'), '.txt')\n",
    "\n",
    "move_files(test_files, images_dir, os.path.join(base_dir, 'test', 'images'), '.png')\n",
    "move_files(test_files, annotations_dir, os.path.join(base_dir, 'test', 'labels'), '.txt')\n",
    "\n",
    "print(\"Dataset generation and organization completed.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T10:07:58.629771800Z",
     "start_time": "2024-02-23T10:07:58.386908800Z"
    }
   },
   "id": "c8ddea2d829eba6f",
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
